[
    {
        "content": " TLDR; I created a small npm package that acts as a wrapper around node-fetch, and returns the same promise for the same request, until it resolves. You can visit the repo of this package here. Below, I explain my motivation, and how I tackled the issue.\nSo here\u0026rsquo;s the scenario:\nYou have a system that interfaces with a really slow third-party API. User Bob, needs some data, so your system performs a request to the third-party API, and waits for a response. In the meantime, user Alice needs the same date and the system performs the same request to the API on behalf of her. Both users are now waiting for two requests that the only difference they have, is the execution time.\nIf a request to this API has an average response time of 1 second, both users will wait 1 second. Also, you would need to occupy resources in your system and the third-party API for more than 1 second, and for 2 seconds at most!\nThe solution What if you could have both users, Bob and Alice, wait for the same request? Then, although Bob will still wait for the request for 1 second, Alice will use Bob\u0026rsquo;s request, and wait less time for the response.\nTo achieve that, we\u0026rsquo;ll need a promise-cache subsystem. This subsystem will consist of a data structure to store our requests\u0026rsquo; promises and of a way to retrieve them/delete them when they are not needed.\nThe data structure We need a data structure to store our promises inside. This data structure needs to be able to store and retrieve a new promise in one operation (O(1)). So, the best choice would be a key/value store. Javascript, offers two such structures, the basic object and the Map() instance. The most preferrable data structure for our use-case among the two is the Map().\nSo, let\u0026rsquo;s create it:\nconst promiseCache: Map\u0026lt;string, Promise\u0026lt;Response\u0026gt;\u0026gt; = new Map(); The retrieval/storage Now, let\u0026rsquo;s create a function that wraps around the request function and retrieves the same promise for the same request, if it exists. If it doesn\u0026rsquo;t, it performs a new request and stores it in the cache.\nfunction memoizedRequest(url: string) { const key = url; if (promiseCache.has(key)) { return promiseCache.get(key); } const promise = request(url); promiseCache.set(key, promise); return promise; } With this, we have achieved the basic function of our promise-cache subsystem. When our system performs a request using the memoizedRequest function, and the request has already happened, it returns the same promise.\nBut, we haven\u0026rsquo;t yet implemented the mechanism for the deletion of the promise from the cache when the promise resolves (when the request returns results)\nThe deletion - cache invalidation For this, we\u0026rsquo;ll create a function that awaits for the promise to resolve and then delete the promise from the cache.\nasync function promiseInvalidator(key: string, promise: Promise\u0026lt;any\u0026gt;) { await promise; promiseCache.delete(key); return promise; } And then we\u0026rsquo;ll modify our memoizedRequest function to include this invalidation function:\nfunction memoizedRequest(url: string) { const key = url; if (promiseCache.has(key)) { return promiseCache.get(key); } const promise = promiseInvalidator(key, request(url)); promiseCache.set(key, promise); return promise; } But what happens with more complicated requests? Not all requests can be differentiated by just the url they are performed on. There are many other parameters that make a request different (eg: headers, body etc).\nFor that, we\u0026rsquo;ll need to refine our promise-cache\u0026rsquo;s key and add an options object on our function:\nfunction memoizedRequest(url: string, options: RequestOptions) { const key = url + JSON.stringify(options); if (promiseCache.has(key)) { return promiseCache.get(key); } const promise = promiseInvalidator(key, request(url)); promiseCache.set(key, promise); return promise; } Now, only the requests that use exactly the same options will return the same promise until they resolve.\nWith this, we implemented all the basic functionality of our package. But we haven\u0026rsquo;t taken into account the possibility of a request failure. Let\u0026rsquo;s add this on our code, by making the promiseInvalidator function to always remove the promise from the cache either when it resolves, or when it rejects.\nasync function promiseInvalidator(key: string, promise: Promise\u0026lt;any\u0026gt;) { try { await promise; } finally { promiseCache.delete(key); } return promise; } More improvements This implementation has a small drawback, that can prove serious on a production system. All the requests\u0026rsquo; data, are stored within the key of our data store, highly increasing the memory requirements of our application, especially when our requests contain a lot of data. The solution to this is to use a hash function on our key, to assign a unique value to each different request, without needing to include all the actual of the request.\nconst key = hasher(url + JSON.stringify(options)); Caveats This solution, isn\u0026rsquo;t applicable to any situation. To use this solution, you need to ensure that the API you are interfacing with, is not providing different responses for two different requests in the amount of time it will take for those requests to resolve.\nThe package If you don\u0026rsquo;t want to code this for yourself, I created a simple npm package that does all of the above, as a wrapper to node-fetch (or any other fetch-like function you choose).\nimport memoizedNodeFetch from \u0026#39;memoized-node-fetch\u0026#39;; const fetch = memoizedNodeFetch(); (async () =\u0026gt; { const fetch1 = fetch(\u0026#39;https://jsonplaceholder.typicode.com/todos/1\u0026#39;); const fetch2 = fetch(\u0026#39;https://jsonplaceholder.typicode.com/todos/1\u0026#39;); // This should return true because both requests return the same promise. console.log(fetch1 === fetch2); const res1 = await fetch1; const res2 = await fetch2; console.log(await res1.json()); console.log(await res2.json()); })(); You can see all of the above work, on its Github repository here:\nhttps://github.com/chrispanag/memoized-node-fetch\nPS. 1: Although this can be used in the front-end, I can\u0026rsquo;t find a very useful use-case for it, especially when you have other packages such as react-query/swr, that although they perform a different function than the above, can sometimes remove the need for it.\nPS. 2: Special thanks to the other two contributors of this repository (ferrybig and Bonjur for their invaluable input and suggestions!\n",
        "permalink": "https://polmoreno.github.io/posts/as-rep-roasting/",
        "summary": "TLDR; I created a small npm package that acts as a wrapper around node-fetch, and returns the same promise for the same request, until it resolves. You can visit the repo of this package here. Below, I explain my motivation, and how I tackled the issue.\nSo here\u0026rsquo;s the scenario:\nYou have a system that interfaces with a really slow third-party API. User Bob, needs some data, so your system performs a request to the third-party API, and waits for a response.",
        "title": "AS-REP ROASTING"
    },
    {
        "content": "After the privacy related changes to WhatsApp, a lot of people are fleeing this popular chat application for other more privacy-aware choices. This development, made me consider Signal, again, as a chat service, but my decision to install it and try to move my contacts was not a privacy related one.\nIn Greece where me and most of my contacts live, WhatsApp isn\u0026rsquo;t as popular as Facebook\u0026rsquo;s Messenger, an app that lacks end-to-end encryption and as a result is considerably worse privacy-wise.\nEnd-to-end encryption is a technical measure, implemented to make eavesdropping on your chat conversations impossible. It encrypts your messages from the moment they leave your device, till the moment they are received by your friend\u0026rsquo;s phone. In this way, nobody can use your conversations to sell your information to advertisers and no rogue government can read your messages to enforce laws. But for the average person living in a western democracy, who still (knowingly or unknowningly) uses Facebook and other ad-supported, privacy-invasive social networks, this feature is not as important as it seems.\nMessenger, for me, is the best chat app in the world, because it has the only feature I need from a chat app. My contacts!\nIf I want to contact somebody, I know that he will be there receiving my messages. This feature is enough for me to give up the promise of enchanced privacy.\nIt\u0026rsquo;s something different that should be more important.\nBut why did I install Signal? Although we feel that we can choose our chat service, the direct opposite happens. The best feature mainstream chat apps have, our contacts\u0026rsquo; usage of them, is the reason we are hostages to these applications. If we want to move to another chat application, we need to pursue all of our contacts to move. This is the great power Facebook is using irresponsibly.\nThis power is what takes away from us the right to choose who and why is using our data.\nBut more importantly, this power hinders innovation and progress. If a better chat application is released, then most people wouldn\u0026rsquo;t care to use it. That happens because it wouldn\u0026rsquo;t have the most important feature, their friends. Eventually, if this application is really better than the current offerings, the best features would be copied by the mainstream apps and the vicious cycle will continue.\nTrying to go against this great power, I installed Signal. I chose Signal because it is in a way the direct opposite of what Facebook\u0026rsquo;s apps are. It is open-source, people can view and contribute to its code and it\u0026rsquo;s backed by a non-profit. It\u0026rsquo;s an app that implements changes based to what its community wants, it\u0026rsquo;s an app that can care about your opinion and your choices.\nI immediately invited my closest contacts to join and\u0026hellip; people joined, then agreed that this app is nice and afterwards nobody contacted me a second time through Signal. Everybody still used Messenger.\nAt the end, I completely understood their choice, or better, their lack of choice. If they wanted to keep in touch with their other friends, they still needed to use Messenger, and who wants to complicate their lives with multiple apps?\nAt the end, what can we do? When the internet started proliferating, choice was one of its biggest advantages. We could choose the software we use, we could choose the services we access. But now, the massive social networks, with the power they have accumulated by our participation, have narrowed down our choices to the bare minimum.\nThe only way to change the situation is to force those social networks to use their powers more responsibly. Europe\u0026rsquo;s GDPR law with its right to data portability is a step in the right direction, but it\u0026rsquo;s not enough. I believe we need more to regain our right to choose what services we use.\nAfter portability, we need to discuss about interoperability, which in this case is the ability to contact people that are are using different chat applications than the one you are using. The way email and SMS already work.\nAlthough this is still far-fetched, we need to finally start addressing it.\nFurther reads What is ActivityPub? Signal: What is it and why is everyone talking about it? How do you feel about the right to choice? I would love to discuss more about it in the comments.\n",
        "permalink": "https://polmoreno.github.io/posts/kerberoasting/",
        "summary": "After the privacy related changes to WhatsApp, a lot of people are fleeing this popular chat application for other more privacy-aware choices. This development, made me consider Signal, again, as a chat service, but my decision to install it and try to move my contacts was not a privacy related one.\nIn Greece where me and most of my contacts live, WhatsApp isn\u0026rsquo;t as popular as Facebook\u0026rsquo;s Messenger, an app that lacks end-to-end encryption and as a result is considerably worse privacy-wise.",
        "title": "KERBEROASTING"
    },
    {
        "content": "My name is Christos Panagiotakopoulos I\u0026rsquo;m a self-proclaimed software craftsman with a 5-year experience in Node.js.\nI\u0026rsquo;m currently building decentralized discourse, as a Software Engineer, at Capsule Social, while exploring the potential of the Decentralized Web.\nI\u0026rsquo;m currently finishing my CS studies at the School of Electrical \u0026amp; Computer Engineering of the National Technical University of Athens.\nIn my free time, I play greek rembetiko music on the guitar and administrate the rembetiko.gr community.\nFrom time to time you can read some of my thoughts, projects and ideas that I share on my blog.\nNotable projects I use, like and support: Discourse (github/website) Mailcow (github/website) Signal (github/website) IPFS (github/website) type-graphql (github/website) ",
        "permalink": "https://polmoreno.github.io/about/",
        "summary": "About",
        "title": ""
    }
]